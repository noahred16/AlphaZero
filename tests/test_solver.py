import pytest
from games.connect4 import Connect4
from util.solver import Solver
from util.mcts import MCTS
import numpy as np


def test_solver_evaluate_state():
    board = np.array(
        [
            [0, 0, 0, 0],
            [1, -1, 0, 0],
            [1, -1, 0, 0],
            [1, -1, 0, 0],
        ],
        dtype=int,
    )
    game = Connect4(num_of_rows=4, num_of_cols=4, board=board)
    board_value = game.evaluate_board()
    assert board_value == None  # since the game is not over yet

    solver = Solver(game)

    # X = 1, O = -1
    # [ _ | _ | _ | _ ]
    # [ X | O | _ | _ ]
    # [ X | O | _ | _ ]
    # [ X | O | _ | _ ]
    #   0   1   2   3

    # value: 1 (X wins next move)
    # policy: [0.68, 0.32, 0, 0]

    policy_label, value_label = solver.evaluate_state()

    assert value_label == 1  # scaled between best and worst score
    assert round(policy_label[0], 2) == 0.68  # best move
    assert round(policy_label[1], 2) == 0.32  # okay move, leads to tie
    assert round(policy_label[2], 2) == 0.0  # bad move, leads to loss
    assert round(policy_label[3], 2) == 0.0  # bad move, leads to loss
    assert round(sum(policy_label), 2) == 1.0  # assert probabilities sum to 1


def test_equal_winning_moves():
    board = np.array(
        [
            [0, 0, 0, 0],
            [1, -1, 1, -1],
            [1, -1, 1, -1],
            [1, -1, 1, -1],
        ],
        dtype=int,
    )
    game = Connect4(num_of_rows=4, num_of_cols=4, board=board)
    solver = Solver(game)
    # Evaluate the state
    policy_label, value_label = solver.evaluate_state()
    # In this case, both column 0 and column 2 are winning moves for player 1 (X).
    assert round(policy_label[0], 2) == 0.5  # equal probability for winning moves
    assert round(policy_label[2], 2) == 0.5  # equal probability for winning moves
    assert round(policy_label[1], 2) == 0.0  # bad move, leads to loss
    assert round(policy_label[3], 2) == 0.0  # bad move, leads to loss
    # X = 1, O = -1
    # [ _ | _ | _ | _ ]
    # [ X | O | X | O ]
    # [ X | O | X | O ]
    # [ X | O | X | O ]
    #   0   1   2   3


def test_tie_game():
    # |O|O| | |
    # |X|X| | |
    # |O|O| | |
    # |X|X| | |
    # ---------------
    # 0 1 2 3
    board = np.array(
        [
            [-1, -1, 0, 0],
            [1, 1, 0, 0],
            [-1, -1, 0, 0],
            [1, 1, 0, 0],  # full board with no winner
        ],
        dtype=int,
    )

    game = Connect4(num_of_rows=4, num_of_cols=4, board=board)
    game.print_pretty()
    board_value = game.evaluate_board()
    assert board_value == None  # tie game

    solver = Solver(game)
    policy_label, value_label = solver.evaluate_state()
    assert value_label == 0


def test_solver_lose():
    # check value is negative and moves are equal since both lead to next move loss
    # |X|X| | |
    # |O|O|O| |
    # |X|X|O|X|
    # |O|O|O|X|
    # ---------------
    # 0 1 2 3
    board = np.array(
        [
            [1, 1, 0, 0],
            [-1, -1, -1, 0],
            [1, 1, -1, 1],
            [-1, -1, -1, 1],
        ],
        dtype=int,
    )
    game = Connect4(num_of_rows=4, num_of_cols=4, board=board)
    game.print_pretty()
    board_value = game.evaluate_board()
    assert board_value == None  # game is not over yet
    solver = Solver(game)
    policy_label, value_label = solver.evaluate_state()
    print("Policy: ", policy_label, "Value: ", value_label)
    assert value_label < 0  # since player 1 (X) is losing
    assert round(policy_label[0], 2) == 0.0  # bad move, leads to loss
    assert round(policy_label[1], 2) == 0.0  # bad move, leads to loss
    assert round(policy_label[2], 2) == 0.5  # okay move, leads to tie
    assert round(policy_label[3], 2) == 0.5  # okay move, leads to tie


def test_solver_empty_board():
    # all moves lead to a tie given optimally play
    game = Connect4(num_of_rows=4, num_of_cols=4)
    solver = Solver(game)

    # evaluation for empty board
    policy_label, value_label = solver.evaluate_state()

    assert value_label == 0
    # assert all moves are 0.25 rounded
    for i in range(4):
        assert round(policy_label[i], 2) == 0.25


def test_mcts_move_probabilities():
    game = Connect4(num_of_rows=4, num_of_cols=4)
    mcts = MCTS(iterations=100)
    move_probs = mcts.search(game)

    # this just checks if the move probs generated by mcts sum to 1
    assert np.isclose(np.sum(move_probs), 1.0)

    # additionally check that illegal moves have zero probability
    legal_moves = game.get_legal_moves()
    for move in range(game.num_of_cols):
        if move not in legal_moves:
            assert move_probs[move] == 0.0


def test_mcts_samples_collection():
    """
    Test that the MCTS implementation records board states and scaled outcomes.
    This ensures that the training data (board state, reward) is well-formed.
    """
    game = Connect4(num_of_rows=4, num_of_cols=4)
    mcts = MCTS(iterations=50)
    mcts.search(game)
    samples = mcts.get_samples()

    # Ensure some samples were collected.
    assert len(samples) > 0

    # Verify each sample has the proper board shape and a reward scaled between -1 and 1.
    for board_state, reward in samples:
        assert board_state.shape == (game.num_of_rows, game.num_of_cols)
        assert -1.0 <= reward <= 1.0


def test_mcts_rollout_win_scaling():
    """
    Test that when a win is achieved quickly for the root player,
    the rollout returns a positive reward scaled as (worst_case - move_count) / worst_case.

    For a 4x4 board, worst_case = 16.
    We simulate a vertical win for player 1 (root player) with the moves:
      p1: 0, p-1: 1, p1: 0, p-1: 1, p1: 0, p-1: 1, p1: 0
    After these 7 moves, player 1 wins. The expected scaling factor is:
      (16 - 7) / 16 = 9/16 ≈ 0.5625.
    """
    # Create a 4x4 Connect4 game
    game = Connect4(num_of_rows=4, num_of_cols=4)

    # Simulate moves:
    # p1 (1) moves in column 0
    game.make_move(0)  # move_count = 1
    # p-1 (-1) moves in column 1
    game.make_move(1)  # move_count = 2
    # p1 moves in column 0
    game.make_move(0)  # move_count = 3
    # p-1 moves in column 1
    game.make_move(1)  # move_count = 4
    # p1 moves in column 0
    game.make_move(0)  # move_count = 5
    # p-1 moves in column 1
    game.make_move(1)  # move_count = 6
    # p1 moves in column 0 --> completes vertical 4 in column 0
    game.make_move(0)  # move_count = 7; win for player 1

    mcts = MCTS(iterations=1)
    # Since the game is already terminal, rollout should immediately return the scaled reward.
    reward = mcts.rollout(game, root_player=1)
    expected = (16 - 7) / 16  # Expected reward ≈ 0.5625
    assert abs(reward - expected) < 1e-5, f"Expected {expected}, got {reward}"


def test_mcts_rollout_loss_scaling():
    """
    Test that when a loss is achieved quickly for the root player,
    the rollout returns a negative reward scaled as -(worst_case - move_count) / worst_case.

    For a 4x4 board, worst_case = 16.
    We simulate a vertical win for the opponent (player -1) with the moves:
      p1: 1, p-1: 0, p1: 1, p-1: 0, p1: 2, p-1: 0, p1: 2, p-1: 0
    After these 8 moves, player -1 wins. The expected scaling factor is:
      (16 - 8) / 16 = 8/16 = 0.5, and since the win is for the opponent, the reward is -0.5.
    """
    # Create a 4x4 Connect4 game
    game = Connect4(num_of_rows=4, num_of_cols=4)

    # Simulate moves:
    # p1 moves in column 1
    game.make_move(1)  # move_count = 1
    # p-1 moves in column 0
    game.make_move(0)  # move_count = 2
    # p1 moves in column 1
    game.make_move(1)  # move_count = 3
    # p-1 moves in column 0
    game.make_move(0)  # move_count = 4
    # p1 moves in column 2
    game.make_move(2)  # move_count = 5
    # p-1 moves in column 0
    game.make_move(0)  # move_count = 6
    # p1 moves in column 2
    game.make_move(2)  # move_count = 7
    # p-1 moves in column 0 --> completes vertical win for player -1 in column 0
    game.make_move(0)  # move_count = 8; win for player -1

    mcts = MCTS(iterations=1)
    # Since the game is terminal with a loss for the root player (1),
    # rollout should immediately return the negative scaled reward.
    reward = mcts.rollout(game, root_player=1)
    expected = (16 - 8) / 16  # Expected reward = -0.5
    assert abs(reward - expected) < 1e-5, f"Expected {expected}, got {reward}"
